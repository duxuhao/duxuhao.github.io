{"name":"Practical Machine Learning Assignment","tagline":"Analysis Description of the Activity Performace","body":"This is the description of the assignment for unit Practical_machine_learning \r\nHere is the process I deal with the data\r\n##\r\n    library(caret)\r\n    data <- read.csv(\"pml-training.csv\")\r\n    FilterData <- data[,colSums(is.na(data)) == 0]\r\n    FilterData <- FilterData[,8:dim(FilterData)[2]]\r\n    FilterData <- FilterData[, sapply(FilterData, is.numeric)]\r\n    tmp <- cor(FilterData[1:dim(FilterData)[2]]) #the corelationsip among each variables\r\n    remove <- findCorrelation(tmp, cutoff = 0.80, verbose = TRUE) #delete the column with high correlation\r\n    FilterData <- FilterData[,-remove]\r\n    FilterData[[\"class\"]] <- data$class #put back the target column as it was deleted by the non-digit delete action\r\n##\r\n\r\nHere, I read the training data and preprocess the data frame with the following step:\r\n1. Remove the column with too many NaN value, since there are too many invalid value in it;\r\n2. Delete the column with non-digit value, which cannot be used for predicting as the value is non-digit;\r\n3. Delete the first few column as they are label of time the user;\r\n4. Put the class column back to the data frame.\r\n\r\n##\r\n    set.seed(1992912)\r\n    inTrain <- createDataPartition(y=FilterData$class,p=0.7,list=FALSE)\r\n\r\n    Training <- FilterData[inTrain,]\r\n    Testing <- FilterData[-inTrain,]\r\n##\r\n\r\nAnd then, I put 70% of data into the training set and 30% into the test set\r\n\r\n##\r\n    PredictionMethod <-c(\"gbm\",\"treebag\",\"nb\",\"rpart\")\r\n    n = 1\r\n    Accuracy <- c(0,0,0,0)\r\n    for (pm in PredictionMethod[1:2]) {\r\n\r\n\tmod <- train(class ~ ., method=pm,data=Training)\r\n\tpre <- predict(mod,newdata=Testing)\r\n\tprint(pm) #print out the method name in order to better view the result\r\n\tImp <- varImp(mod,scale = FALSE)\r\n\tprint(Imp) #print out the importance of different variables\r\n\tprint(confusionMatrix(pre,Testing$class))\r\n\tperformance <- confusionMatrix(pre,Testing$class)\r\n\tAccuracy[n] <- performance$overall[1]\r\n\tif (n > 1) {\r\n\t\tif (Accuracy[n] > Accuracy[n-1]) {\r\n\t\t\tUsedMod <- mod # if this method is more accuracy than the last one, pick up this one \r\n\t\t}\r\n\t} else {\r\n\t\tUsedMod <- mod\r\n\t}\r\n\tn <- n + 1\r\n\r\n    }\r\n\r\n    testdata <- read.csv(\"pml-testing.csv\")\r\n\r\n    testpre <- predict(UsedMod,newdata=testdata)\r\n    print(testpre)\r\n##\r\n\r\nI choose the first 4 comonly used method for predicting and print out the accuracy of each method. I made a loop\r\nfor training and if the accuracy of this method is higher than the last method, the method will be marked down and\r\nthe method with the highest accuracy will be puck up, which turns out to be the \"treebag\" method. The accuracies \r\nare marked in the Model_Performance_result.txt file the here is the one of the \"treebag\" method:\r\n\r\n              Reference\r\n    Prediction    A    B    C    D    E\r\n             A 1665   16    0    4    1\r\n             B    5 1105    7    0    2\r\n             C    2   16 1000   13    3\r\n             D    2    2   16  947    6\r\n             E    0    0    3    0 1070\r\n\r\n\r\nOverall Statistics\r\n                                          \r\n               Accuracy : 0.9833          \r\n                 95% CI : (0.9797, 0.9865)\r\n    No Information Rate : 0.2845          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.9789          \r\n     Mcnemar's Test P-Value : 0.009824        \r\n \r\n     whose predicted value is \r\n \r\n First Prediction\r\n\r\n [1] B A B A A E D B A A B C B A E E A B B B\r\nLevels: A B C D E\r\n\r\nAnd I also use the \"random Forest\" method to do the classification:\r\n\r\n##\r\n    modrf <- train(class ~ ., method='rf',data=Training)\r\n    prerf <- predict(modrf,newdata=Testing)\r\n    print(\"random forest\")\r\n    Imprf <- varImp(modrf, scale = FALSE)\r\n    print(Imprf)\r\n    print(confusionMatrix(prerf,Testing$class))\r\n    testpre <- predict(modrf,newdata=testdata)\r\n    print(testpre)\r\n##\r\n\r\nThe training result is followed:\r\n\r\n              Reference\r\n    Prediction    A    B    C    D    E\r\n             A 1673   10    0    0    0\r\n             B    1 1119    5    0    0\r\n             C    0    9 1011    8    3\r\n             D    0    0   10  956    4\r\n             E    0    1    0    0 1075\r\n\r\nOverall Statistics\r\n                                          \r\n               Accuracy : 0.9913          \r\n                 95% CI : (0.9886, 0.9935)\r\n    No Information Rate : 0.2845          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.989           \r\n Mcnemar's Test P-Value : NA              \r\n\r\nthe accuracy is a bit higher than the tree bag method (99.1% > 98.3%) and they got the same prediction result from the testing set\r\n\r\n [1] B A B A A E D B A A B C B A E E A B B B\r\nLevels: A B C D E\r\n\r\nAnd the top 20 importance of the variables are:\r\n\r\n![](https://raw.githubusercontent.com/duxuhao/Practical_Machine_Learning/master/Importance.png)\r\n\r\nSo here is the result I got from this data set.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}